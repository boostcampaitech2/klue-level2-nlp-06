  {
    "wandb":{
      "name" : "roberta_large_stratified",
      "tags" : ["ROBERT_LARGE", "stratified", "10epoch"], 
      "group" : "MLM"
    },

    "aug_family": false,
    "type_ent_marker": false,
    "type_punct":false,
    "tok_len" : 256,

    "train":{
      "focal_loss":{
        "true" : false,
        "alpha" : 0.1,
        "gamma" : 0.25
      },

      "TrainingArguments" : {
        "output_dir":"./results",          
        "save_total_limit":1,              
        "save_steps":100,                 
        "num_train_epochs":10,              
        "learning_rate":5e-5,               
        "per_device_train_batch_size":38,  
        "per_device_eval_batch_size":38,   
        "warmup_steps":500,                
        "weight_decay":0.01,               
        "logging_dir":"./logs",            
        "logging_steps":100,              
        "evaluation_strategy":"steps", 
        "eval_steps" : 100,            
        "load_best_model_at_end" : true
      },
      "early_stop": {
        "true" : false,
        "patience" : 5
      }
      
    },
    

    "model" :{
      "huggingface": "klue/roberta-large",
      "config":{
        "num_labels" : 30
      }
    }
  }